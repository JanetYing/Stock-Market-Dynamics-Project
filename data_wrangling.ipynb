{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from scipy.stats import t\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Janet/OneDrive - The University of Chicago/Data_policy/final-project-janet'\n",
    "\n",
    "file_name = 'output.csv'\n",
    "file_path = os.path.join(path, file_name)\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "event_date = datetime(2018, 6, 28) # date of CCPA being signed\n",
    "estimation_window_start = event_date - timedelta(days=365)\n",
    "estimation_window_end = event_date - timedelta(days=30)\n",
    "event_window_start = event_date - timedelta(days=10)\n",
    "event_window_end = event_date + timedelta(days=10)\n",
    "stock_list = df['ticker'].unique()\n",
    "# stock_list = ['ATUS', 'AFTM', 'ATUS', 'AAPL', 'ARRY']  # List of stocks to analyze\n",
    "\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "for ticker in stock_list:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        \n",
    "        # Fetch historical stock data using yf.download\n",
    "        historical_data_adjClose = yf.download(ticker, start=estimation_window_start, end=event_window_end) #retrieved dataframe that include adj close column\n",
    "        if historical_data_adjClose.empty:\n",
    "            print(f\"No data for {ticker} using yf.download for specified dates.\")\n",
    "            continue\n",
    "\n",
    "        # Fetch historical stock data using stock.history\n",
    "        historical_data_dividend = stock.history(start=estimation_window_start, end=event_window_end) #retrieved dataframe that include dividend column\n",
    "        if historical_data_dividend.empty:\n",
    "            print(f\"No data for {ticker} using stock.history for specified dates.\")\n",
    "            continue\n",
    "\n",
    "        # Convert both DataFrames to tz-naive (if they are tz-aware)\n",
    "        historical_data_adjClose.index = historical_data_adjClose.index.tz_localize(None)\n",
    "        historical_data_dividend.index = historical_data_dividend.index.tz_localize(None)\n",
    "\n",
    "        # Merge the two dataframes on their index since both are indexed by date when retrieved\n",
    "        historical_data = pd.merge(historical_data_adjClose, historical_data_dividend[['Dividends']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "        historical_data['ticker'] = ticker\n",
    "\n",
    "        info = stock.info\n",
    "        market_cap = info.get('marketCap', 'N/A')\n",
    "        historical_data['marketCap'] = market_cap\n",
    "\n",
    "        # Append this stock's data to the combined DataFrame\n",
    "        combined_data = pd.concat([combined_data, historical_data])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "market_index_ticker = '^GSPC'  # Example: S&P 500\n",
    "market_data = yf.download(market_index_ticker, start=estimation_window_start, end=event_window_end)\n",
    "market_data = market_data[['Adj Close']].rename(columns={'Adj Close': 'market_adj_close'})\n",
    "combined_data = combined_data.rename(columns={\n",
    "    'Adj Close': 'stock_adj_close',\n",
    "    'Volume': 'stock_volume',\n",
    "    'Open': 'stock_open',\n",
    "    'High': 'stock_high',\n",
    "    'Low': 'stock_low',\n",
    "    'Close': 'stock_close',\n",
    "    'Dividends':'dividends',\n",
    "    'marketCap':'stock_market_cap'\n",
    "})\n",
    "combined_data = combined_data.rename_axis('date')\n",
    "market_data = market_data.rename_axis('date')\n",
    "merged_data = pd.merge(combined_data, market_data, left_index=True, right_index=True, how='left')\n",
    "# merged_data = pd.merge(historical_data_adjClose, historical_data_dividend[['Dividends']], left_index=True, right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "98\n",
      "19666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "unique_ticker_count = combined_data['ticker'].nunique()\n",
    "print(unique_ticker_count)\n",
    "print(combined_data['dividends'].nunique())\n",
    "print(combined_data['stock_volume'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_path = r'C:\\Users\\Janet\\OneDrive - The University of Chicago\\Data_policy\\final-project-janet\\data'\n",
    "json_file_name = 'sp500_constituents.json'\n",
    "json_file_path = os.path.join(sp500_path, json_file_name)\n",
    "with open(json_file_path, 'r') as file:\n",
    "    sp500_data = json.load(file)\n",
    "sp500_tickers = sp500_data.get(\"2018/06/20\", []) #extract sp500 constitutes list at the most recent date of event_date (2018/6/28)\n",
    "merged_data['sp500'] = merged_data['ticker'].apply(lambda x: 1 if x in sp500_tickers else 0)\n",
    "\n",
    "merged_data.to_csv('combined_stock_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances where sp500 equals 1: 3870\n"
     ]
    }
   ],
   "source": [
    "sp500_counts = merged_data['sp500'].value_counts()\n",
    "count_sp500_is_1 = sp500_counts.get(1, 0)\n",
    "print(\"Number of instances where sp500 equals 1:\", count_sp500_is_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
